# -*- coding: utf-8 -*-
from pymongo import MongoClient
import time
from datetime import datetime
import readMongo
from wordCloudLDAModel import get_word_cloud

client = MongoClient('localhost', 40000)
db = client.lavector
collection = db.wordcloud

'''
å‘æ•°æ®åº“ä¸­å†™å…¥æ•°æ®
'''

'''
æŒ‰æ ¼å¼å†™å…¥æ•°æ®åº“
    {
    _id:ObjectId(),
    words : [
        {word : weight},
        {word : weight}
     ],
    projectId : WordCloud
    tC: ISODate(yyyy-MM-ddThh:mm:sssZ),
    source: weibo,
    brand: â€œå¥¥è¿ªâ€
    }
å¯¹å•ä¸ªå­—çš„è¯æœ‰ä¸€ä¸ªç™½åå•ï¼Œåœ¨è¿™ä¸ªç™½åå•ä¸­çš„å•ä¸ªå­—çš„è¯æ‰èƒ½æ”¾å…¥è¯äº‘åˆ—è¡¨ä¸­
'''
white_list = [u'å¥½', u'å¤§', u'å°', u'è´µ', u'å¿«', u'æ£’', u'å®½', u'é•¿', u'é’±', u'ğŸˆ¶ï¸æ²¹']


def write_words(word_list, cal_time, brand, key, begin, end):
    '''0.002*æ‰‹æœº + 0.002*å­©å­ + 0.001*çƒ + 0.001*é«˜æ ¡'''
    word = []
    words = []
    # for result in results:
    #     if result['keywords'][0] == brand:
    #         project_id = result['_id']
    #         break
    for wl in word_list:
        str = wl[1].strip().split('+')
        for s in str:
            ss = s.strip().split('*')
            if ss[1].strip() not in word:
                if len(ss[1]) == 1 and ss[1] not in white_list:
                    continue
                word.append(ss[1])
                words.append({ss[1].strip(): ss[0].strip()})

    '''å–å‡ºæ¯ä¸ªä¸»é¢˜çš„ç¬¬ä¸€ä¸ªè¯(å¯ä»¥å•ç‹¬å†™ä¸€ä¸ªå‡½æ•°)'''
    '''
    for wl in word_list:  # æ¯ä¸ªä¸»é¢˜
        str = wl.strip().split('+')  # æ¯ä¸ªä¸»é¢˜çš„ç¬¬ä¸€ä¸ªè¯
        weight_word = str[0].split('*')

        if weight_word[1].strip() not in word:
            word.append(weight_word[1].strip())
            words.append({weight_word[1].strip(): weight_word[0].strip()})
    '''
    # post = {
    #     "words": words,
    #     "projectId": project_id,
    #     "tC": cal_time,
    #     "begin": datetime.strptime(begin, '%Y-%m-%d %H:%M:%S'),
    #     "end": datetime.strptime(end, '%Y-%m-%d %H:%M:%S'),
    #     "source": key,
    #     "brand": brand
    # }
    # if project_id != -1:
    #     collection.insert(post)
    #     print 'insert success !'


def write_mongo(begin, end, brand):
    """
    å°†æŒ‡å®šæ—¥æœŸå†…çš„,æŒ‡å®šå“ç‰Œ,æŒ‡å®šå†…å®¹æ¥æºçš„è¯--æƒé‡å†™å¦‚æ•°æ®åº“
    begin:å¼€å§‹æ—¥æœŸ
    end:ç»“æŸæ—¥æœŸ
    brand:æŒ‡å®šå“ç‰Œ
    """
    if begin > end:
        return False
    content_dic = readMongo.get_content(begin, end, brand)  # å–å‡ºç‰¹å®šå“ç‰Œçš„content
    print 'è¯»å–æ‰€æœ‰æ¥æºå†…å®¹æˆåŠŸ'
    for key, value in content_dic.items():
        print 'åˆ†æ' + key + 'æ¥æº'
        if len(value) < 2:
            print 'source ' + key + ' content is too small !'
        else:
            word_list = get_word_cloud(value)  # è¯--æƒé‡
            if word_list is not None:
                # è®¡ç®—æ—¶çš„æ—¶é—´,è½¬æ¢ä¸ºISODateæ ¼å¼
                cal_time = datetime.strptime(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), '%Y-%m-%d %H:%M:%S')
                write_words(word_list, cal_time, brand, key, begin, end)


'''è¾“å‡ºldaæ•ˆæœï¼Œcsvæ–‡ä»¶'''
import csv

def print_lda(begin, end, brand, time):

    content_dic = readMongo.get_content(begin, end, brand)  # å–å‡ºç‰¹å®šå“ç‰Œçš„content
    print 'è¯»å–æ•°æ®æˆåŠŸ'
    for key, value in content_dic.items():
        print key, len(value)
        if len(value) < 2:
            print 'source ' + key + ' content is too small !'
        else:
            word_list = get_word_cloud(value)  # è¯--æƒé‡
            save_name = 'lda' + str(key.encode('utf-8')) + str(brand.encode('utf-8')) + '2.csv'
            csvfile = file(save_name, 'wb')
            writer = csv.writer(csvfile)
            writer.writerow(['topic_id', 'word', 'weight', 'delete_y'])
            if word_list is not None:
                for w_l in word_list:
                    print w_l[0]
                    pairs = w_l[1].split('+')
                    for pair in pairs:
                        weight_word = pair.split('*')
                        writer.writerow([str(w_l[0]), str(weight_word[1].encode('utf-8')), str(weight_word[0].encode('utf-8')), ''])
            csvfile.close()
#
#
# pos = codecs.open('./posdict.txt', encoding='utf-8').read().split('\n')
# neg = codecs.open('./negdict.txt', encoding='utf-8').read().split('\n')
# '''è¾“å‡ºldaæ•ˆæœï¼Œcsvæ–‡ä»¶'''
#
#

# def print_lda_filter(begin, end, brand, time):
#     content_dic = readMongo.get_content(begin, end, brand)  # å–å‡ºç‰¹å®šå“ç‰Œçš„content
#     value = content_dic['xcar']
#     if len(value) < 2:
#         print 'source ' + 'xcar' + ' content is too small !'
#     else:
#         word_list = get_word_cloud(value)  # è¯--æƒé‡
#         save_name = brand + str(time) + '.txt'
#         with open(save_name, 'w') as wr:
#             if word_list is not None:
#                 for w_l in word_list:
#                     result = ''
#                     wr.write('topic' + str(w_l[0]) + '#')
#                     ss = w_l[1].strip().split('+')
#                     for s in ss:
#                         ww = s.strip().split('*')
#                         if ww[1] in pos or ww[1] in neg:
#                             result += str(ww[1]) + ':' + str(ww[0]) + ' '
#                     wr.write(result + '\r\n')
